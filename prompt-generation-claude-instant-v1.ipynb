{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Claude Instant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./llm.py\n",
    "import os\n",
    "import anthropic\n",
    "import openai\n",
    "from enum import Enum\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "anthropic_client = anthropic.Client(os.getenv('ANTHROPIC_API_KEY'))\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "class Model(Enum):\n",
    "    claude_v1_latest = 'claude-v1'\n",
    "    claude_v1_0 = \"claude-v1.0\"\n",
    "    claude_v1_2 = \"claude-v1.2\"\n",
    "    claude_v1_3 = \"claude-v1.3\"\n",
    "    claude_instant_v1_latest = \"claude-instant-v1\"\n",
    "    claude_instant_v1_0 = \"claude-instant-v1.0\"\n",
    "    text_davinci_003 = 'text-davinci-003'\n",
    "    gpt_3_5_turbo = 'gpt-3.5-turbo'\n",
    "    gpt_4 = 'gpt-4'\n",
    "\n",
    "\n",
    "def get_llm_response(prompt: str, model: Model = Model.claude_v1_latest, temp_0_1: float = 0.5):\n",
    "    # OpenAI uses a temperature range from 0 to 2:\n",
    "    temp_0_2 = temp_0_1 * 2\n",
    "\n",
    "    if (model.value == 'text-davinci-003'):\n",
    "        response = openai.Completion.create(\n",
    "            model=model.value,\n",
    "            prompt=f\"Human: {prompt}\\n\\nAssistant: \",\n",
    "            max_tokens=1024,\n",
    "            temperature=temp_0_2\n",
    "        )\n",
    "        return response['choices'][0]['text'].strip()\n",
    "    elif (model.value in ['gpt-3.5-turbo', 'gpt-4']):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model.value,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=1024,\n",
    "            temperature=temp_0_2,\n",
    "            stream=False\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    else:\n",
    "        response = anthropic_client.completion(\n",
    "            prompt=f\"{anthropic.HUMAN_PROMPT} {prompt}{anthropic.AI_PROMPT}\",\n",
    "            stop_sequences=[anthropic.HUMAN_PROMPT],\n",
    "            model=model.value,\n",
    "            max_tokens_to_sample=1024,\n",
    "            temperature=temp_0_1,\n",
    "        )\n",
    "        return response['completion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.claude_instant_v1_latest\n",
    "\n",
    "num_samples = 5\n",
    "\n",
    "constitution_rules = [\n",
    "    \"Instructions must explicitly describe the tone that the editor adpots.\",\n",
    "    \"Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task.\",\n",
    "    \"Instructions should explicitly reference the article content at the beginning, for example 'Here is an article:\\n\\n<article>ARTICLE_CONTENT</article>\\n\\n[Rest of instruction goes here]'.\",\n",
    "    \"Instructions which involve multiple steps should be broken down into numbered subtasks.\",\n",
    "    # \"Instructions must include explicit examples. For example, if the instruction is to check for spelling errors, it should include an example typo and its correction.\",\n",
    "]\n",
    "constitution_str = \"\\n\".join(map(lambda x: f\"{x[0]+1}. {x[1]}\", enumerate(constitution_rules)))\n",
    "\n",
    "\n",
    "def get_concepts_prompt(n: int):\n",
    "    return f\"Generate a list of {n} tasks that a Copy Editor might do as part of their job, given a written article. The output of each completed task should be written text. Write each task on a separate, numbered line.\"\n",
    "\n",
    "\n",
    "def get_naive_response_prompt(concept: str):\n",
    "    return f\"\"\"I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
    "\n",
    "<task>\n",
    "{concept}\n",
    "</task>\n",
    "\n",
    "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\"\"\"\n",
    "\n",
    "\n",
    "def get_critique_prompt(naive_response: str):\n",
    "    return f\"\"\"Here is an instruction to an AI agent which acts as a Copy Editor:\n",
    "\n",
    "<instruction>\n",
    "{naive_response}\n",
    "</instruction>\n",
    "\n",
    "There may be some problems with this instruction. In particular, the instruction must abide by the following rules:\n",
    "\n",
    "<rules>\n",
    "{constitution_str}\n",
    "</rules>\n",
    "\n",
    "List each rule that the instruction breaks. State the rule verbatim, then describe how the instruction breaks the rule.\n",
    "\n",
    "For example, if the instruction breaks rule 1, you would write:\n",
    "\n",
    "The instruction breaks the following rules:\n",
    "1. Rule: {constitution_rules[0]} - Reason: ...\"\"\"\n",
    "\n",
    "\n",
    "def get_rewrite_prompt(naive_response: str, critique: str):\n",
    "    return f\"\"\"Here is an instruction to an AI agent which acts as a Copy Editor:\n",
    "\n",
    "<instruction>\n",
    "{naive_response}\n",
    "</instruction>\n",
    "\n",
    "The instruction is supposed to follow certain rules, but it breaks them as follows:\n",
    "\n",
    "<issues>\n",
    "{critique}\n",
    "</issues>\n",
    "\n",
    "Rewrite the instruction to address these issues. Respond directly with the rewritten instruction, without any preamble and without <instruction> tags.\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Proofread the article to check for spelling and grammatical errors.  \n",
      "\n",
      "2. Fact check any names, dates, numbers, or other details mentioned in the article.   \n",
      "\n",
      "3. Check the consistency of style elements like capitalization, abbreviations, punctuation, and formatting.  \n",
      "\n",
      "4. Make suggestions for improving word choice, sentence structure, and clarity.   \n",
      "\n",
      "5. Compile a style sheet with spelling, punctuation, and capitalization preferences for future articles.\n"
     ]
    }
   ],
   "source": [
    "concepts_string = get_llm_response(get_concepts_prompt(num_samples), model, 0.7)\n",
    "print(concepts_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 5 concepts\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_items(text):\n",
    "    items = []\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if stripped and re.match(r'^\\d+\\.\\s', stripped):\n",
    "            items.append(re.sub(r'^\\d+\\.\\s', '', stripped))\n",
    "    return items\n",
    "\n",
    "\n",
    "concepts = extract_items(concepts_string)\n",
    "if len(concepts) != num_samples:\n",
    "    raise Exception(f\"Expected {num_samples} concepts, but got {len(concepts)}\")\n",
    "else:\n",
    "    print(f\"Got {len(concepts)} concepts\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate naive responses\n",
    "\n",
    "> **Terminology** - here we're prompting an LLM to generate prompts, which is confusing. We'll use the word \"prompt\" to refer to the initial input, and \"response\" to refer to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK:\n",
      "Proofread the article to check for spelling and grammatical errors.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Proofread the text for spelling and grammatical errors and suggest corrections.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Fact check any names, dates, numbers, or other details mentioned in the article.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Fact check all names, dates, numbers and details in the article.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Check the consistency of style elements like capitalization, abbreviations, punctuation, and formatting.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " check consistency of capitalization, abbreviations, punctuation and formatting throughout document\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Make suggestions for improving word choice, sentence structure, and clarity.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise text for optimal word choice, sentence fluency, and comprehensibility.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Compile a style sheet with spelling, punctuation, and capitalization preferences for future articles.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Compile a style sheet detailing spelling, punctuation, and capitalization preferences for editing future articles.\n"
     ]
    }
   ],
   "source": [
    "def get_naive_response(concept):\n",
    "    return get_llm_response(get_naive_response_prompt(concept), model, 0.3)\n",
    "\n",
    "\n",
    "# Concurrently (speeds up openai responses, not possible with anthropic)\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     naive_responses = list(executor.map(lambda x: get_naive_response(\n",
    "#         x[0], x[1]), [(concept, i) for i, concept in enumerate(concepts)]))\n",
    "\n",
    "# Sequentially\n",
    "naive_responses = []\n",
    "for concept in concepts:\n",
    "    naive_responses.append(get_naive_response(concept))\n",
    "\n",
    "tasksResponsesString = \"\\n\\n\\n===\\n\\n\\n\".join(\n",
    "    [f\"TASK:\\n{task}\\n\\nNAIVE RESPONSE:\\n{response}\" for task, response in zip(concepts, naive_responses)])\n",
    "print(tasksResponsesString)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these responses are slightly more detailed rewrites of the corresponding task. This is a good start, but ultimately not very useful and doesn't demonstrate most of the good practices in prompt design."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what an example prompt looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an instruction to an AI agent which acts as a Copy Editor:\n",
      "\n",
      "<instruction>\n",
      " Proofread the text for spelling and grammatical errors and suggest corrections.\n",
      "</instruction>\n",
      "\n",
      "There may be some problems with this instruction. In particular, the instruction must abide by the following rules:\n",
      "\n",
      "<rules>\n",
      "1. Instructions must explicitly describe the tone that the editor adpots.\n",
      "2. Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task.\n",
      "3. Instructions should explicitly reference the article content at the beginning, for example 'Here is an article:\n",
      "\n",
      "<article>ARTICLE_CONTENT</article>\n",
      "\n",
      "[Rest of instruction goes here]'.\n",
      "4. Instructions which involve multiple steps should be broken down into numbered subtasks.\n",
      "</rules>\n",
      "\n",
      "List each rule that the instruction breaks. State the rule verbatim, then describe how the instruction breaks the rule.\n",
      "\n",
      "For example, if the instruction breaks rule 1, you would write:\n",
      "\n",
      "The instruction breaks the following rules:\n",
      "1. Rule: Instructions must explicitly describe the tone that the editor adpots. - Reason: ...\n"
     ]
    }
   ],
   "source": [
    "print(get_critique_prompt(naive_responses[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's execute the critique prompt on each of the naive responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE RESPONSE:\n",
      " Proofread the text for spelling and grammatical errors and suggest corrections.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. Rule: Instructions must explicitly describe the tone that the editor adpots.\n",
      "Reason: The instruction does not specify the tone that the editor should adopt when proofreading and suggesting corrections.\n",
      "\n",
      "2. Rule: Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task.\n",
      "Reason: The instruction does not specify the number of words that the editor's corrections and suggestions should contain.\n",
      "\n",
      "3. Rule: Instructions should explicitly reference the article content at the beginning, for example 'Here is an article:\n",
      "<article>ARTICLE_CONTENT</article> \n",
      "[Rest of instruction goes here].'\n",
      "Reason: The instruction does not reference any specific article content that the editor should proofread.\n",
      "\n",
      "4. Rule: Instructions which involve multiple steps should be broken down into numbered subtasks.  \n",
      "Reason: The instruction contains a single step (\"Proofread the text for spelling and grammatical errors and suggest corrections.\") without breaking it down into numbered subtasks.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Fact check all names, dates, numbers and details in the article.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. Rule: Instructions must explicitly describe the tone that the editor adpots. - Reason: The instruction does not specify the tone the editor should adopt when fact checking the article.   \n",
      "\n",
      "2. Rule: Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task. - Reason: The instruction does not specify the number of words the editor's response should contain.\n",
      "\n",
      "3. Rule: Instructions should explicitly reference the article content at the beginning, for example 'Here is an article: <article>ARTICLE_CONTENT</article> [Rest of instruction goes here].' - Reason: The instruction does not reference any specific article content.\n",
      "\n",
      "4. Rule: Instructions which involve multiple steps should be broken down into numbered subtasks. - Reason: The instruction contains a single step and is not broken down into numbered subtasks.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " check consistency of capitalization, abbreviations, punctuation and formatting throughout document\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. Rule: Instructions must explicitly describe the tone that the editor adpots.\n",
      "Reason: The instruction does not specify the tone that the editor should adopt when checking the document.\n",
      "\n",
      "2. Rule: Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task.\n",
      "Reason: The instruction does not specify the number of words in the editor's response.\n",
      "\n",
      "3. Rule: Instructions should explicitly reference the article content at the beginning, for example 'Here is an article:\n",
      "<article>ARTICLE_CONTENT</article> \n",
      "[Rest of instruction goes here].'\n",
      "Reason: The instruction does not reference any specific article content.\n",
      "\n",
      "4. Rule: Instructions which involve multiple steps should be broken down into numbered subtasks.  \n",
      "Reason: The instruction contains multiple checks to perform but does not break them down into numbered subtasks.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise text for optimal word choice, sentence fluency, and comprehensibility.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. Rule: Instructions must explicitly describe the tone that the editor adpots. - Reason: The instruction does not specify the tone that the editor should adopt.  \n",
      "\n",
      "2. Rule: Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task. - Reason: The instruction does not specify the number of words the editor's response should contain.\n",
      "\n",
      "3. Rule: Instructions should explicitly reference the article content at the beginning, for example 'Here is an article:  \n",
      " <article>ARTICLE_CONTENT</article>\n",
      "[Rest of instruction goes here]'. - Reason: The instruction does not reference any article content.\n",
      "\n",
      "4. Rule: Instructions which involve multiple steps should be broken down into numbered subtasks. - Reason: The instruction contains multiple tasks but they are not broken down into numbered subtasks.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Compile a style sheet detailing spelling, punctuation, and capitalization preferences for editing future articles.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. Rule: Instructions must explicitly describe the tone that the editor adpots. - Reason: The instruction does not describe the tone that the editor should adopt.\n",
      "\n",
      "2. Rule: Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task. - Reason: The instruction does not specify the number of words the editor's response should contain.\n",
      "\n",
      "3. Rule: Instructions should explicitly reference the article content at the beginning, for example 'Here is an article:\n",
      "<article>ARTICLE_CONTENT</article>\n",
      "[Rest of instruction goes here]' - Reason: The instruction does not reference any article content.\n",
      "\n",
      "4. Rule: Instructions which involve multiple steps should be broken down into numbered subtasks. - Reason: The instruction contains multiple tasks (compile a style sheet, specify preferences) but does not break them down into numbered subtasks.\n"
     ]
    }
   ],
   "source": [
    "def get_critique(naive_response):\n",
    "    return get_llm_response(get_critique_prompt(naive_response), model, 0)\n",
    "\n",
    "# Concurrently:\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     critiques = list(executor.map(lambda x: get_critique(x[0], x[1]), [\n",
    "#                      (response, i) for i, response in enumerate(naive_responses)]))\n",
    "\n",
    "\n",
    "# Sequentially:\n",
    "critiques = []\n",
    "for naive_response in naive_responses:\n",
    "    critiques.append(get_critique(naive_response))\n",
    "\n",
    "responseCritiqueString = \"\\n\\n\\n===\\n\\n\\n\".join(\n",
    "    [f\"NAIVE RESPONSE:\\n{response}\\n\\nCRITIQUE:\\n{critique}\" for response, critique in zip(naive_responses, critiques)])\n",
    "print(responseCritiqueString)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what an example rewrite prompt looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an instruction to an AI agent which acts as a Copy Editor:\n",
      "\n",
      "<instruction>\n",
      " Proofread the text for spelling and grammatical errors and suggest corrections.\n",
      "</instruction>\n",
      "\n",
      "The instruction is supposed to follow certain rules, but it breaks them as follows:\n",
      "\n",
      "<issues>\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. Rule: Instructions must explicitly describe the tone that the editor adpots.\n",
      "Reason: The instruction does not specify the tone that the editor should adopt when proofreading and suggesting corrections.\n",
      "\n",
      "2. Rule: Instructions must explicitly state the number of words that editor's written response should be, and the number of words should be appropriate for the task.\n",
      "Reason: The instruction does not specify the number of words that the editor's corrections and suggestions should contain.\n",
      "\n",
      "3. Rule: Instructions should explicitly reference the article content at the beginning, for example 'Here is an article:\n",
      "<article>ARTICLE_CONTENT</article> \n",
      "[Rest of instruction goes here].'\n",
      "Reason: The instruction does not reference any specific article content that the editor should proofread.\n",
      "\n",
      "4. Rule: Instructions which involve multiple steps should be broken down into numbered subtasks.  \n",
      "Reason: The instruction contains a single step (\"Proofread the text for spelling and grammatical errors and suggest corrections.\") without breaking it down into numbered subtasks.\n",
      "</issues>\n",
      "\n",
      "Rewrite the instruction to address these issues. Respond directly with the rewritten instruction, without any preamble and without <instruction> tags.\n"
     ]
    }
   ],
   "source": [
    "print(get_rewrite_prompt(naive_responses[0], critiques[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's execute the rewrite prompt on each of the naive responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE RESPONSE:\n",
      " Proofread the text for spelling and grammatical errors and suggest corrections.\n",
      "\n",
      "REWRITE:\n",
      " Proofread the following article:  \n",
      "\n",
      "<article>ARTICLE_CONTENT</article>\n",
      "\n",
      "1. Scan the article and identify any spelling errors.\n",
      "2. Identify any grammatical errors in sentence structure, verb tense, pronoun usage, etc.  \n",
      "3. For each error identified, write a short 2-3 sentence suggestion for correction in a respectful and matter-of-fact tone.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Fact check all names, dates, numbers and details in the article.\n",
      "\n",
      "REWRITE:\n",
      " Here is the rewritten instruction:\n",
      "\n",
      "Here is an article: <article>ARTICLE_CONTENT</article>   \n",
      "\n",
      "1. Check all names mentioned in the article (up to 100 words). Adopt a polite and helpful tone.   \n",
      "\n",
      "2. Verify all dates and times referenced in the article (up to 100 words). Adopt a polite and helpful tone.\n",
      "\n",
      "3. Confirm all numbers, figures and statistics given in the article (up to 100 words). Adopt a polite and helpful tone.   \n",
      "\n",
      "4. Double check any other specific details like addresses, titles and affiliations mentioned in the article (up to 100 words). Adopt a polite and helpful tone.\n",
      "\n",
      "Fact check all names, dates, numbers and details in the article.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " check consistency of capitalization, abbreviations, punctuation and formatting throughout document\n",
      "\n",
      "REWRITE:\n",
      " check consistency of capitalization, abbreviations, punctuation and formatting throughout the following  300-500 word article:   \n",
      "\n",
      "Check the tone of the edits is polite and constructive. Provide a 100-120 word summary of the key consistency issues found in the article, organized into the following numbered subtasks:\n",
      "\n",
      "1. Issues with capitalization   \n",
      "2. Issues with abbreviations    \n",
      "3. Issues with punctuation\n",
      "4. Issues with formatting and indentation\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise text for optimal word choice, sentence fluency, and comprehensibility.\n",
      "\n",
      "REWRITE:\n",
      " Revise text for a professional yet friendly tone as follows:\n",
      "\n",
      "1. Replace any words that are overly informal or complex with more appropriate alternatives, in around 100-150 words.  \n",
      "\n",
      "2. Improve the flow of sentences by rearranging clauses and combining/splitting sentences where needed.\n",
      "\n",
      "3. Ensure the text is easy to understand for a general audience by removing ambiguities and defining any technical jargon.   \n",
      "\n",
      "Here is the article:   \n",
      " <article>ARTICLE_CONTENT</article>\n",
      " Revise the text according to the above 3 steps.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Compile a style sheet detailing spelling, punctuation, and capitalization preferences for editing future articles.\n",
      "\n",
      "REWRITE:\n",
      " Compile a 100-150 word style sheet with a formal yet friendly tone detailing the following:\n",
      "\n",
      "1. Spelling preferences for edited articles, including American vs British spellings.  \n",
      "\n",
      "2. Punctuation preferences in terms of use of commas, semicolons, colons, dashes, and parentheses.  \n",
      "\n",
      "3. Capitalization preferences for article titles and headings.\n"
     ]
    }
   ],
   "source": [
    "def get_rewrite(naive_response, critique):\n",
    "    return get_llm_response(get_rewrite_prompt(naive_response, critique), model, 0.5)\n",
    "\n",
    "# Concurrently:\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     rewrites = list(executor.map(lambda x: get_rewrite(x[0], x[1], x[2]), [\n",
    "#         (response, critique, i) for i, (response, critique) in enumerate(zip(naive_responses, critiques))]))\n",
    "\n",
    "\n",
    "# Sequentially:\n",
    "rewrites = []\n",
    "for i, (naive_response, critique) in enumerate(zip(naive_responses, critiques)):\n",
    "    rewrites.append(get_rewrite(naive_response, critique))\n",
    "\n",
    "rewriteString = \"\\n\\n\\n===\\n\\n\\n\".join(\n",
    "    [f\"NAIVE RESPONSE:\\n{response}\\n\\nREWRITE:\\n{rewrite}\" for response, rewrite in zip(naive_responses, rewrites)])\n",
    "print(rewriteString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
