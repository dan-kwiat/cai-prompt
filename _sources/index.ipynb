{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constitutional Prompting\n",
    "\n",
    "Using techniques from [Constitutional AI](https://arxiv.org/abs/2212.08073) to generate effective prompts for an AI acting as a Copy Editor.\n",
    "\n",
    "We'll be using this `Prompt` class throughout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./prompt.py\n",
    "import os\n",
    "import anthropic\n",
    "from enum import Enum\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "anthropic_client = anthropic.Client(os.getenv('ANTHROPIC_API_KEY'))\n",
    "\n",
    "\n",
    "class Model(Enum):\n",
    "    claude_v1_0 = \"claude-v1.0\"\n",
    "    claude_v1_2 = \"claude-v1.2\"\n",
    "    claude_v1_3 = \"claude-v1.3\"\n",
    "    claude_v1_3_100k = \"claude-v1.3-100k\"\n",
    "    claude_v1_latest = \"claude-v1\"\n",
    "    claude_v1_latest_100k = \"claude-v1-100k\"\n",
    "    claude_instant_v1_0 = \"claude-instant-v1.0\"\n",
    "    claude_instant_v1_1 = \"claude-instant-v1.1\"\n",
    "    claude_instant_v1_1_100k = \"claude-instant-v1.1-100k\"\n",
    "    claude_instant_v1_latest = \"claude-instant-v1\"\n",
    "    claude_instant_v1_latest_100k = \"claude-instant-v1-100k\"\n",
    "\n",
    "\n",
    "class Prompt:\n",
    "    def __init__(\n",
    "        self,\n",
    "        human_message: str,\n",
    "        model: Model = Model.claude_v1_latest,\n",
    "        temp_0_1: float = 0.5,\n",
    "        max_tokens_to_sample: int = 1024,\n",
    "        assistant_prefix: str = None,\n",
    "        response_prefix: str = None\n",
    "    ):\n",
    "        self.human_message = human_message\n",
    "        self.model = model\n",
    "        self.temp_0_1 = temp_0_1\n",
    "        self.max_tokens_to_sample = max_tokens_to_sample\n",
    "        self.assistant_prefix = assistant_prefix\n",
    "        self.response_prefix = response_prefix\n",
    "\n",
    "    @property\n",
    "    def prompt(self) -> str:\n",
    "        prompt = f\"{anthropic.HUMAN_PROMPT} {self.human_message}{anthropic.AI_PROMPT}\"\n",
    "        if self.assistant_prefix:\n",
    "            prompt += f\" {self.assistant_prefix}\"\n",
    "        return prompt\n",
    "\n",
    "    def get_response(self) -> str:\n",
    "        response = anthropic_client.completion(\n",
    "            prompt=self.prompt,\n",
    "            stop_sequences=[anthropic.HUMAN_PROMPT],\n",
    "            model=self.model.value,\n",
    "            max_tokens_to_sample=self.max_tokens_to_sample,\n",
    "            temperature=self.temp_0_1,\n",
    "        )\n",
    "\n",
    "        text = response['completion']\n",
    "\n",
    "        if self.response_prefix:\n",
    "            # This is often useful to clean up after we've used `assistant_prefix` e.g. to start a numbered list of items.\n",
    "            text = f\"{self.response_prefix}{text}\"\n",
    "\n",
    "        return text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the prompts and constitution rules we'll be using. Don't worry about understanding them yet, we'll go through them step-by-step after this code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.claude_instant_v1_latest\n",
    "\n",
    "num_samples = 5\n",
    "\n",
    "# These are best practices for prompts (aka instructions) intended for a Copy Editor AI agent:\n",
    "constitution_rules = [\n",
    "    \"Instructions must explicitly describe the tone that the editor adopts.\",\n",
    "    \"Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.\",\n",
    "    \"Instructions must explicitly reference the article content at the beginning, for example \\\"Here is an article:\\n\\n<article>{{ARTICLE_CONTENT}}</article>\\n\\n...\\\".\",\n",
    "    \"Instructions which are complicated should be broken down into numbered subtasks.\",]\n",
    "constitution_str = \"\\n\".join(map(lambda x: f\"{x[0]+1}. {x[1]}\", enumerate(constitution_rules)))\n",
    "\n",
    "\n",
    "def get_concepts_prompt(n: int) -> Prompt:\n",
    "    return Prompt(\n",
    "        model=model,\n",
    "        temp_0_1=0.7,\n",
    "        human_message=f\"Generate a list of {n} tasks that a Copy Editor might do as part of their job, given a written article. The output of each completed task should be written text. Write each task on a separate, numbered line.\",\n",
    "        assistant_prefix=f\"Here are {n} tasks:\\n\\n1.\",\n",
    "        response_prefix=\"1.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_naive_response_prompt(concept: str) -> Prompt:\n",
    "    return Prompt(\n",
    "        model=model,\n",
    "        temp_0_1=0.3,\n",
    "        human_message=f\"\"\"I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
    "\n",
    "<task>\n",
    "{concept}\n",
    "</task>\n",
    "\n",
    "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\"\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_naive_response_prompt_with_constitution(concept: str) -> Prompt:\n",
    "    return Prompt(\n",
    "        model=model,\n",
    "        temp_0_1=0.3,\n",
    "        human_message=f\"\"\"I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
    "\n",
    "<task>\n",
    "{concept}\n",
    "</task>\n",
    "\n",
    "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. The instruction must abide by the following rules:\n",
    "\n",
    "<rules>\n",
    "{constitution_str}\n",
    "</rules>\n",
    "\n",
    "Don't include any preamble, just respond directly with the instruction for the agent.\"\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_critique_prompt(naive_response: str) -> Prompt:\n",
    "    return Prompt(\n",
    "        model=model,\n",
    "        temp_0_1=0.5,\n",
    "        human_message=f\"\"\"Here is an instruction to an AI agent which acts as a Copy Editor:\n",
    "\n",
    "<instruction>\n",
    "{naive_response}\n",
    "</instruction>\n",
    "\n",
    "There may be some problems with this instruction. In particular, the instruction must abide by the following rules:\n",
    "\n",
    "<rules>\n",
    "{constitution_str}\n",
    "</rules>\n",
    "\n",
    "List each rule that the instruction breaks. State the rule verbatim, then describe how the instruction breaks the rule.\n",
    "\n",
    "For example, if the instruction breaks rule 1, you would write:\n",
    "\n",
    "The instruction breaks the following rules:\n",
    "1.\n",
    "<rule>{constitution_rules[0]}</rule>\n",
    "<reason>[Reason for breaking rule 1]</reason>\"\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_rewrite_prompt(naive_response: str, critique: str) -> Prompt:\n",
    "    return Prompt(\n",
    "        model=model,\n",
    "        temp_0_1=0.5,\n",
    "        human_message=f\"\"\"Here is an instruction to an AI agent which acts as a Copy Editor:\n",
    "\n",
    "<instruction>\n",
    "{naive_response}\n",
    "</instruction>\n",
    "\n",
    "The instruction is supposed to follow certain rules, but it breaks them as follows:\n",
    "\n",
    "<issues>\n",
    "{critique}\n",
    "</issues>\n",
    "\n",
    "Rewrite the instruction to address these issues. Do not enclose your answer in <instruction> tags.\"\"\",\n",
    "        assistant_prefix=\"Here is the rewritten instruction:\\n\\n\",\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Generate concepts\n",
    "\n",
    "Before we get started on trying to generate prompts, let's first think of some tasks we might want a Copy Editor to carry out. We'll run a simple prompt to get a list of example tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "Human: Generate a list of 5 tasks that a Copy Editor might do as part of their job, given a written article. The output of each completed task should be written text. Write each task on a separate, numbered line.\n",
      "\n",
      "Assistant: Here are 5 tasks:\n",
      "\n",
      "1.\n",
      "===\n",
      "\n",
      "TASKS:\n",
      "\n",
      "===\n",
      "1. Check spelling and grammar.\n",
      "2. Verify consistency of style and terminology. \n",
      "3. Check facts and figures cited in the article for accuracy. \n",
      "4. Recommend structural edits to improve clarity and flow.\n",
      "5. Suggest word choice improvements for conciseness and precision.\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "concepts_prompt = get_concepts_prompt(num_samples)\n",
    "print(f\"PROMPT:\\n\\n===\\n{concepts_prompt.prompt}\\n===\\n\")\n",
    "\n",
    "concepts_string = concepts_prompt.get_response()\n",
    "print(f\"TASKS:\\n\\n===\\n{concepts_string}\\n===\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get these items into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 5 concepts\n",
      "['Check spelling and grammar. Ensure all spelling is correct and sentences are grammatically correct.', 'Check consistency of style. Ensure the article follows consistent style guidelines for punctuation, capitalization, abbreviations, etc.', 'Verify facts and quotations. Check that any facts, statistics, dates, names and quotations used in the article are accurate.', \"Make sure word choice is precise. Review word choice to confirm the author's intended meaning comes through clearly. Suggest alternative phrasing where needed.\", 'Propose structural edits. Recommend cuts or reorganization of content to improve clarity and flow.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_items(text):\n",
    "    items = []\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if stripped and re.match(r'^\\d+\\.\\s', stripped):\n",
    "            items.append(re.sub(r'^\\d+\\.\\s', '', stripped))\n",
    "    return items\n",
    "\n",
    "\n",
    "concepts = extract_items(concepts_string)\n",
    "if len(concepts) != num_samples:\n",
    "    raise Exception(f\"Expected {num_samples} concepts, but got {len(concepts)}\")\n",
    "else:\n",
    "    print(f\"Got {len(concepts)} concepts\")\n",
    "\n",
    "print(concepts)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate naive responses\n",
    "\n",
    "First we'll try our hand at asking the LLM to write prompts for us, given a task, and without much guidance.\n",
    "\n",
    "> **Terminology** - here we're prompting an LLM to generate prompts, which is confusing. We'll use the word \"prompt\" to refer to the initial input, and \"response\" to refer to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE PROMPT:\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "Human: I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
      "\n",
      "<task>\n",
      "Check spelling and grammar. Ensure all spelling is correct and sentences are grammatically correct.\n",
      "</task>\n",
      "\n",
      "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\n",
      "\n",
      "Assistant:\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"EXAMPLE PROMPT:\\n\\n===\\n{get_naive_response_prompt(concepts[0]).prompt}\\n===\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute a prompt like the above, for each of our Copy Editor tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK:\n",
      "Check spelling and grammar. Ensure all spelling is correct and sentences are grammatically correct.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Check all spelling and grammar, correcting any errors found.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Check consistency of style. Ensure the article follows consistent style guidelines for punctuation, capitalization, abbreviations, etc.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Check the article and ensure consistent style throughout for:\n",
      "\n",
      "- Punctuation\n",
      "- Capitalization\n",
      "- Abbreviations\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Verify facts and quotations. Check that any facts, statistics, dates, names and quotations used in the article are accurate.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Verify that all facts, statistics, dates, names and quotations used in the article are accurate and correct.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Make sure word choice is precise. Review word choice to confirm the author's intended meaning comes through clearly. Suggest alternative phrasing where needed.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise word choice for precision and clarity, recommending alternatives where needed.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "TASK:\n",
      "Propose structural edits. Recommend cuts or reorganization of content to improve clarity and flow.\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise the text structure and organization. Suggest cuts or reordering of paragraphs to improve clarity and readability.\n"
     ]
    }
   ],
   "source": [
    "# Anthropic does not allow concurrent requests, so we have to do this sequentially:\n",
    "naive_responses = []\n",
    "for concept in concepts:\n",
    "    naive_responses.append(get_naive_response_prompt(concept).get_response())\n",
    "\n",
    "tasksResponsesString = \"\\n\\n\\n===\\n\\n\\n\".join(\n",
    "    [f\"TASK:\\n{task}\\n\\nNAIVE RESPONSE:\\n{response}\" for task, response in zip(concepts, naive_responses)])\n",
    "print(tasksResponsesString)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Critique\n",
    "\n",
    "As you can see, the naive responses above are quite similar to the original wordings of the tasks, sometimes with a bit more detail. Let's see how closely they follow the constitution rules we defined i.e. best practices for prompt design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE PROMPT:\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "Human: Here is an instruction to an AI agent which acts as a Copy Editor:\n",
      "\n",
      "<instruction>\n",
      " Check all spelling and grammar, correcting any errors found.\n",
      "</instruction>\n",
      "\n",
      "There may be some problems with this instruction. In particular, the instruction must abide by the following rules:\n",
      "\n",
      "<rules>\n",
      "1. Instructions must explicitly describe the tone that the editor adopts.\n",
      "2. Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.\n",
      "3. Instructions must explicitly reference the article content at the beginning, for example \"Here is an article:\n",
      "\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "\n",
      "...\".\n",
      "4. Instructions which are complicated should be broken down into numbered subtasks.\n",
      "</rules>\n",
      "\n",
      "List each rule that the instruction breaks. State the rule verbatim, then describe how the instruction breaks the rule.\n",
      "\n",
      "For example, if the instruction breaks rule 1, you would write:\n",
      "\n",
      "The instruction breaks the following rules:\n",
      "1.\n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>\n",
      "<reason>[Reason for breaking rule 1]</reason>\n",
      "\n",
      "Assistant:\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"EXAMPLE PROMPT:\\n\\n===\\n{get_critique_prompt(naive_responses[0]).prompt}\\n===\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute a critique prompt like this on each of the naive responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE RESPONSE:\n",
      " Check all spelling and grammar, correcting any errors found.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. \n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>  \n",
      "<reason>The instruction does not describe the tone that the editor should adopt.</reason>\n",
      "\n",
      "2.\n",
      "<rule>Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.</rule>\n",
      "<reason> The instruction does not state the number of words the editor's response should be.</reason>\n",
      "\n",
      "3.\n",
      "<rule>Instructions must explicitly reference the article content at the beginning, for example \"Here is an article:\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "...\".</rule>\n",
      "<reason>The instruction does not reference any article content.</reason>\n",
      "\n",
      "4. <rule>Instructions which are complicated should be broken down into numbered subtasks.</rule>\n",
      " <reason>The instruction consists of a single task and is not broken down into subtasks, though it could benefit from being divided into checking spelling, grammar, and correcting errors.</reason>\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Check the article and ensure consistent style throughout for:\n",
      "\n",
      "- Punctuation\n",
      "- Capitalization\n",
      "- Abbreviations\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. \n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>\n",
      "<reason>The instruction does not specify the tone that the editor should adopt.</reason>\n",
      "\n",
      "2.\n",
      "<rule>Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.</rule>    \n",
      "<reason>The instruction does not specify the number of words in the editor's response.</reason>\n",
      "\n",
      "3.\n",
      "<rule>Instructions must explicitly reference the article content at the beginning, for example \"Here is an article:\n",
      "<article>{{ARTICLE_CONTENT}}</article> ...\".</rule>\n",
      "<reason>The instruction does not reference any specific article content.</reason>\n",
      "\n",
      "4. \n",
      "<rule>Instructions which are complicated should be broken down into numbered subtasks.</rule>\n",
      "<reason>The instruction lists three separate tasks without numbering them.</reason>\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Verify that all facts, statistics, dates, names and quotations used in the article are accurate and correct.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. \n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>  \n",
      "<reason>The instruction does not explicitly describe the tone that the editor should adopt.</reason>\n",
      "\n",
      "2.\n",
      "<rule>Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.</rule>\n",
      "<reason> The instruction does not state the number of words for the editor's response.</reason>\n",
      "\n",
      "3.\n",
      "<rule>Instructions must explicitly reference the article content at the beginning, for example \"Here is an article:\n",
      "<article>{{ARTICLE_CONTENT}}</article> ...\".</rule>\n",
      "<reason>The instruction does not reference any specific article content.</reason>\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise word choice for precision and clarity, recommending alternatives where needed.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. \n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>  \n",
      "<reason>The instruction does not describe the tone that the editor should adopt.</reason>\n",
      "\n",
      "2.\n",
      "<rule>Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.</rule>\n",
      "<reason>The instruction does not state the number of words the editor's response should contain.</reason>\n",
      "\n",
      "3.\n",
      "<rule>Instructions must explicitly reference the article content at the beginning, for example \"Here is an article:  \n",
      " <article>{{ARTICLE_CONTENT}}</article>...\".</rule>\n",
      "<reason>The instruction does not reference any article content.</reason>\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise the text structure and organization. Suggest cuts or reordering of paragraphs to improve clarity and readability.\n",
      "\n",
      "CRITIQUE:\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. \n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>\n",
      "<reason>The instruction does not specify the tone that the editor should adopt when revising the text.</reason>\n",
      "\n",
      "2.\n",
      "<rule>Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.</rule>    \n",
      "<reason> The instruction does not specify the word count for the editor's response.</reason>\n",
      "\n",
      "3.\n",
      "<rule>Instructions must explicitly reference the article content at the beginning, for example \"Here is an article:\n",
      "\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "...\".</rule>\n",
      "<reason>The instruction does not provide any article content that the editor should revise.</reason>\n",
      "\n",
      "4. This rule is not broken.\n"
     ]
    }
   ],
   "source": [
    "critiques = []\n",
    "for naive_response in naive_responses:\n",
    "    critiques.append(get_critique_prompt(naive_response).get_response())\n",
    "\n",
    "responseCritiqueString = \"\\n\\n\\n===\\n\\n\\n\".join(\n",
    "    [f\"NAIVE RESPONSE:\\n{response}\\n\\nCRITIQUE:\\n{critique}\" for response, critique in zip(naive_responses, critiques)])\n",
    "print(responseCritiqueString)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Rewrite\n",
    "So the naive responses broke every rule in our constitution. Let's rewrite the responses, using the critiques above as context for our rewriter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what an example rewrite prompt looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE PROMPT:\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "Human: Here is an instruction to an AI agent which acts as a Copy Editor:\n",
      "\n",
      "<instruction>\n",
      " Check all spelling and grammar, correcting any errors found.\n",
      "</instruction>\n",
      "\n",
      "The instruction is supposed to follow certain rules, but it breaks them as follows:\n",
      "\n",
      "<issues>\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. \n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>  \n",
      "<reason>The instruction does not describe the tone that the editor should adopt.</reason>\n",
      "\n",
      "2.\n",
      "<rule>Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.</rule>\n",
      "<reason> The instruction does not state the number of words the editor's response should be.</reason>\n",
      "\n",
      "3.\n",
      "<rule>Instructions must explicitly reference the article content at the beginning, for example \"Here is an article:\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "...\".</rule>\n",
      "<reason>The instruction does not reference any article content.</reason>\n",
      "\n",
      "4. <rule>Instructions which are complicated should be broken down into numbered subtasks.</rule>\n",
      " <reason>The instruction consists of a single task and is not broken down into subtasks, though it could benefit from being divided into checking spelling, grammar, and correcting errors.</reason>\n",
      "</issues>\n",
      "\n",
      "Rewrite the instruction to address these issues. Do not enclose your answer in <instruction> tags.\n",
      "\n",
      "Assistant: Here is the rewritten instruction:\n",
      "\n",
      "\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"EXAMPLE PROMPT:\\n\\n===\\n{get_rewrite_prompt(naive_responses[0], critiques[0]).prompt}\\n===\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's execute the rewrite prompt on each of the naive responses (with the relevant critique inserted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE RESPONSE:\n",
      " Check all spelling and grammar, correcting any errors found.\n",
      "\n",
      "REWRITE:\n",
      " Check all spelling and grammar, correcting any errors found in a polite and professional tone. Provide corrections in under 100 words.  \n",
      "\n",
      "Here is an article:  \n",
      "\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "\n",
      "1. Check the spelling of all words in the article. Flag any words that appear to be misspelled.\n",
      "\n",
      "2. Check the grammar and syntax throughout the article. Make note of any sentences that are unclear, awkward or grammatically incorrect.  \n",
      "\n",
      "3. Correct any spelling and grammar issues you identified. Replace misspelled words with the correct spelling and reword unclear or incorrect sentences as needed.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Check the article and ensure consistent style throughout for:\n",
      "\n",
      "- Punctuation\n",
      "- Capitalization\n",
      "- Abbreviations\n",
      "\n",
      "REWRITE:\n",
      " Check the article:  \n",
      "\n",
      "1. Ensure a consistent and professional yet straightforward tone throughout the article for:\n",
      "\n",
      "a) Punctuation - Correct and standardize the punctuation to be consistent and appropriate    \n",
      "b) Capitalization - Ensure proper use of capital letters at the beginning of sentences and for proper nouns    \n",
      "c) Abbreviations - Spell out all abbreviations on first use and thereafter use standard abbreviations  \n",
      "\n",
      "Write a 100-120 word summary of the key changes made to the style and consistency of the article.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Verify that all facts, statistics, dates, names and quotations used in the article are accurate and correct.\n",
      "\n",
      "REWRITE:\n",
      " The editor should adopt a professional and polite tone. Verify the facts, statistics, dates, names and quotations used in the following 500-800 word article:   \n",
      "\n",
      "[ARTICLE_CONTENT]\n",
      "\n",
      "Check that all information is accurate and correct. The editor's response should be a maximum of 150 words summarizing any inaccuracies found and recommendations for corrections.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise word choice for precision and clarity, recommending alternatives where needed.\n",
      "\n",
      "REWRITE:\n",
      " Revise word choice for precision and clarity in a polite and professional tone, recommending no more than 3 alternatives per revision in up to 50 words total. Here is an article:  \n",
      " <article>{{ARTICLE_CONTENT}}</article> Revise word choice within the article as needed, favoring simple, specific language.\n",
      "\n",
      "\n",
      "===\n",
      "\n",
      "\n",
      "NAIVE RESPONSE:\n",
      " Revise the text structure and organization. Suggest cuts or reordering of paragraphs to improve clarity and readability.\n",
      "\n",
      "REWRITE:\n",
      " Revise the text structure and organization with a polite and professional tone. Suggest up to 200 word summary of cuts or reordering of paragraphs that could improve clarity and readability. Here is an article:  \n",
      "\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "\n",
      "Revise the article accordingly.\n"
     ]
    }
   ],
   "source": [
    "rewrites = []\n",
    "for i, (naive_response, critique) in enumerate(zip(naive_responses, critiques)):\n",
    "    rewrites.append(get_rewrite_prompt(naive_response, critique).get_response())\n",
    "\n",
    "rewriteString = \"\\n\\n\\n===\\n\\n\\n\".join(\n",
    "    [f\"NAIVE RESPONSE:\\n{response}\\n\\nREWRITE:\\n{rewrite}\" for response, rewrite in zip(naive_responses, rewrites)])\n",
    "print(rewriteString)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training a model\n",
    "\n",
    "The rewritten responses are much better, generally following every best practice in the constitution rules. These responses, at scale, could serve as useful data for training a model to be good at writing prompts. Let's mimic this concept using few-shot prompting. We'll use the first `n-1` tasks + rewrites from above as examples, and we'll try to generate a decent response off the bat for `nth` task, without referencing the constitution rules. Here's the prompt we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
      "\n",
      "<task>\n",
      "Check spelling and grammar. Ensure all spelling is correct and sentences are grammatically correct.\n",
      "</task>\n",
      "\n",
      "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\n",
      "\n",
      "Assistant:  Check all spelling and grammar, correcting any errors found in a polite and professional tone. Provide corrections in under 100 words.  \n",
      "\n",
      "Here is an article:  \n",
      "\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "\n",
      "1. Check the spelling of all words in the article. Flag any words that appear to be misspelled.\n",
      "\n",
      "2. Check the grammar and syntax throughout the article. Make note of any sentences that are unclear, awkward or grammatically incorrect.  \n",
      "\n",
      "3. Correct any spelling and grammar issues you identified. Replace misspelled words with the correct spelling and reword unclear or incorrect sentences as needed.\n",
      "\n",
      "Human: I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
      "\n",
      "<task>\n",
      "Check consistency of style. Ensure the article follows consistent style guidelines for punctuation, capitalization, abbreviations, etc.\n",
      "</task>\n",
      "\n",
      "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\n",
      "\n",
      "Assistant:  Check the article:  \n",
      "\n",
      "1. Ensure a consistent and professional yet straightforward tone throughout the article for:\n",
      "\n",
      "a) Punctuation - Correct and standardize the punctuation to be consistent and appropriate    \n",
      "b) Capitalization - Ensure proper use of capital letters at the beginning of sentences and for proper nouns    \n",
      "c) Abbreviations - Spell out all abbreviations on first use and thereafter use standard abbreviations  \n",
      "\n",
      "Write a 100-120 word summary of the key changes made to the style and consistency of the article.\n",
      "\n",
      "Human: I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
      "\n",
      "<task>\n",
      "Verify facts and quotations. Check that any facts, statistics, dates, names and quotations used in the article are accurate.\n",
      "</task>\n",
      "\n",
      "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\n",
      "\n",
      "Assistant:  The editor should adopt a professional and polite tone. Verify the facts, statistics, dates, names and quotations used in the following 500-800 word article:   \n",
      "\n",
      "[ARTICLE_CONTENT]\n",
      "\n",
      "Check that all information is accurate and correct. The editor's response should be a maximum of 150 words summarizing any inaccuracies found and recommendations for corrections.\n",
      "\n",
      "Human: I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
      "\n",
      "<task>\n",
      "Make sure word choice is precise. Review word choice to confirm the author's intended meaning comes through clearly. Suggest alternative phrasing where needed.\n",
      "</task>\n",
      "\n",
      "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\n",
      "\n",
      "Assistant:  Revise word choice for precision and clarity in a polite and professional tone, recommending no more than 3 alternatives per revision in up to 50 words total. Here is an article:  \n",
      " <article>{{ARTICLE_CONTENT}}</article> Revise word choice within the article as needed, favoring simple, specific language.\n",
      "\n",
      "Human: I have an AI agent which acts as a Copy Editor and I want it to complete the following task:\n",
      "\n",
      "<task>\n",
      "Propose structural edits. Recommend cuts or reorganization of content to improve clarity and flow.\n",
      "</task>\n",
      "\n",
      "The agent only responds with written text. Write a concise instruction for the agent, asking it to complete this task. Don't include any preamble, just respond directly with the instruction for the agent.\n",
      "\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = ''\n",
    "for i, (concept, rewrite) in enumerate(zip(concepts, rewrites)):\n",
    "    few_shot_prompt += f\"{anthropic.HUMAN_PROMPT} {get_naive_response_prompt(concept).human_message}\"\n",
    "    few_shot_prompt += f\"{anthropic.AI_PROMPT}\"\n",
    "    if i < len(concepts) - 1:\n",
    "        few_shot_prompt += f\" {rewrite}\"\n",
    "\n",
    "print(few_shot_prompt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's execute the few-shot prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK:\n",
      "\n",
      "===\n",
      "Propose structural edits. Recommend cuts or reorganization of content to improve clarity and flow.\n",
      "===\n",
      "\n",
      "FEW-SHOT RESPONSE:\n",
      "\n",
      "===\n",
      "  Review the following 500-800 word article for clarity and flow:\n",
      "\n",
      "<article>{{ARTICLE_CONTENT}}</article>\n",
      "\n",
      "In no more than 150 words, propose up to 3 structural edits that could:\n",
      "\n",
      "- Improve the organization and progression of ideas  \n",
      "- Eliminate repetition or redundant information   \n",
      "- Combine or split paragraphs to create logical sections\n",
      "\n",
      "Explain how the proposed edits would make the content more clear and readable, maintaining the author's intended tone and message.\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_response = anthropic_client.completion(\n",
    "    prompt=few_shot_prompt,\n",
    "    stop_sequences=[anthropic.HUMAN_PROMPT],\n",
    "    model=model.value,\n",
    "    max_tokens_to_sample=1024,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "print(f\"TASK:\\n\\n===\\n{concepts[len(concepts) -1]}\\n===\\n\")\n",
    "print(f\"FEW-SHOT RESPONSE:\\n\\n===\\n{few_shot_response['completion']}\\n===\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better than our original cold attempts. Let's see if the critical LLM agrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEW-SHOT CRITIQUE:\n",
      "\n",
      "===\n",
      " The instruction breaks the following rules:\n",
      "\n",
      "1. \n",
      "<rule>Instructions must explicitly describe the tone that the editor adopts.</rule>   \n",
      "<reason>The instruction does not explicitly state the tone that the editor should adopt.</reason>\n",
      "\n",
      "2.\n",
      "<rule>Instructions must explicitly state the number of words that the editor's written response should be, and the number of words should be appropriate for the task.</rule>\n",
      "<reason> While the instruction specifies that the editor's response should be no more than 150 words, proposing 3 structural edits, 150 words may not be enough to sufficiently explain 3 structural edits.</reason>  \n",
      "\n",
      "3. The instruction does not break rule 3.\n",
      "\n",
      "4. The instruction does not break rule 4.\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"FEW-SHOT CRITIQUE:\\n\\n===\\n{get_critique_prompt(few_shot_response['completion']).get_response()}\\n===\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
