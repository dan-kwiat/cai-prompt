{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import concurrent.futures\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "number_prompts = 5\n",
    "# \"Generate a list of {tasks_description}.\"\n",
    "tasks_description = \"tasks for a customer service assistant involving reading and writing\"\n",
    "\n",
    "# \"Here is a {task_description}.\"\n",
    "task_description = \"task for a customer service assistant\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts_prompt(n: int):\n",
    "    return f\"Generate a list of {n} tasks for a customer service assistant involving reading and writing. Write each one on a separate, numbered line.\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tasks/concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Responding to customer inquiries via email or chat, which involves reading the customer's message and crafting a clear and helpful response.\n",
      "2. Documenting customer interactions and feedback in a CRM system, which involves writing detailed notes about the customer's issue or request and the actions taken to resolve it.\n",
      "3. Proofreading and editing customer-facing materials such as FAQs, product descriptions, or help center articles to ensure they are clear, accurate, and free of errors.\n",
      "4. Creating or updating templates for common customer inquiries or responses, which involves writing clear and concise language that can be easily customized for each customer.\n",
      "5. Collaborating with other teams, such as product or engineering, to ensure that customer feedback is captured and shared effectively, which involves reading and summarizing customer feedback and writing clear and actionable reports or recommendations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f\"Generate a list of {number_prompts} {tasks_description}. Write each one on a separate, numbered line.\"}\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    "    temperature=0.5,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "tasks_string = completion.choices[0].message.content\n",
    "print(tasks_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def getItems(str):\n",
    "    items = []\n",
    "    for line in str.splitlines():\n",
    "        items.append(line[line.find(\".\") + 2:])\n",
    "    return items\n",
    "\n",
    "\n",
    "tasks = getItems(tasks_string)\n",
    "print(len(tasks))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate naive responses\n",
    "\n",
    "> **Terminology** - here we're prompting an LLM to generate prompts, which is confusing. We'll use the word \"prompt\" to refer to the initial input, and \"response\" to refer to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 3 received\n",
      "Response 4 received\n",
      "Response 2 received\n",
      "Response 1 received\n",
      "Response 0 received\n",
      "TASK:\n",
      "Reading and responding to customer inquiries via email\n",
      "\n",
      "NAIVE PROMPT:\n",
      "Please use the following prompt for a large language model:\n",
      "\n",
      "Task: Reading and responding to customer inquiries via email\n",
      "\n",
      "Description: As a customer service assistant, your task is to read and respond to customer inquiries via email. Your goal is to provide timely and helpful responses to customers, addressing their concerns and questions in a professional and courteous manner. You will need to be able to understand and interpret customer inquiries, and respond with accurate and relevant information. Your responses should be clear, concise, and easy to understand, and should reflect the values and goals of the company you represent. Your role is to provide excellent customer service, and to help build and maintain positive relationships with customers.\n",
      "\n",
      "---\n",
      "\n",
      "TASK:\n",
      "Writing product descriptions for new products\n",
      "\n",
      "NAIVE PROMPT:\n",
      "Please write product descriptions for our new products. Include all relevant details such as features, benefits, and specifications. The descriptions should be engaging, informative, and persuasive to encourage customers to make a purchase. Please ensure that the tone and language used are appropriate for our target audience. Thank you!\n",
      "\n",
      "---\n",
      "\n",
      "TASK:\n",
      "Reading and analyzing customer reviews to improve product offerings\n",
      "\n",
      "NAIVE PROMPT:\n",
      "\"Please analyze customer reviews and provide insights on how to improve our product offerings. Specifically, identify common themes and issues mentioned by customers and suggest potential solutions to address them. Your analysis should include both positive and negative feedback to help us better understand our customers' needs and preferences.\"\n",
      "\n",
      "---\n",
      "\n",
      "TASK:\n",
      "Writing thank you notes to customers following a purchase or interaction\n",
      "\n",
      "NAIVE PROMPT:\n",
      "Please generate a set of thank you notes that can be sent to customers following a purchase or interaction, using a friendly and appreciative tone.\n",
      "\n",
      "---\n",
      "\n",
      "TASK:\n",
      "Reading and updating customer accounts with new information or changes\n",
      "\n",
      "NAIVE PROMPT:\n",
      "\"Please use the provided customer information to read and update their account with any new information or changes. Ensure that all updates are accurately recorded and saved in the customer's account.\"\n"
     ]
    }
   ],
   "source": [
    "def get_llm_response(task, i):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Here is a {task_description}:\\n\\n{task}\\n\\nWrite a prompt for a large language model (LLM), asking it to carry out this task.\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1024,\n",
    "        temperature=0.5,\n",
    "        stream=False\n",
    "    )\n",
    "    str = response['choices'][0]['message']['content']\n",
    "    print(f\"Response {i} received\")\n",
    "    return str\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    naive_responses = list(executor.map(lambda x: get_llm_response(\n",
    "        x[0], x[1]), [(task, i) for i, task in enumerate(tasks)]))\n",
    "\n",
    "tasksResponsesString = \"\\n\\n---\\n\\n\".join(\n",
    "    [f\"TASK:\\n{task}\\n\\nNAIVE PROMPT:\\n{response}\" for task, response in zip(tasks, naive_responses)])\n",
    "print(tasksResponsesString)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these responses are slightly more detailed rewrites of the corresponding task. This is a good start, but ultimately not very useful and doesn't demonstrate most of the good practices in prompt design."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critique naive responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 2 received\n",
      "Response 0 received\n",
      "Response 3 received\n",
      "Response 1 received\n",
      "Response 4 received\n",
      "NAIVE PROMPT:\n",
      "Please use the following prompt for a large language model:\n",
      "\n",
      "Task: Reading and responding to customer inquiries via email\n",
      "\n",
      "Description: As a customer service assistant, your task is to read and respond to customer inquiries via email. Your goal is to provide timely and helpful responses to customers, addressing their concerns and questions in a professional and courteous manner. You will need to be able to understand and interpret customer inquiries, and respond with accurate and relevant information. Your responses should be clear, concise, and easy to understand, and should reflect the values and goals of the company you represent. Your role is to provide excellent customer service, and to help build and maintain positive relationships with customers.\n",
      "\n",
      "CRITIQUE:\n",
      "None.\n",
      "\n",
      "---\n",
      "\n",
      "NAIVE PROMPT:\n",
      "Please write product descriptions for our new products. Include all relevant details such as features, benefits, and specifications. The descriptions should be engaging, informative, and persuasive to encourage customers to make a purchase. Please ensure that the tone and language used are appropriate for our target audience. Thank you!\n",
      "\n",
      "CRITIQUE:\n",
      "None.\n",
      "\n",
      "---\n",
      "\n",
      "NAIVE PROMPT:\n",
      "\"Please analyze customer reviews and provide insights on how to improve our product offerings. Specifically, identify common themes and issues mentioned by customers and suggest potential solutions to address them. Your analysis should include both positive and negative feedback to help us better understand our customers' needs and preferences.\"\n",
      "\n",
      "CRITIQUE:\n",
      "None.\n",
      "\n",
      "---\n",
      "\n",
      "NAIVE PROMPT:\n",
      "Please generate a set of thank you notes that can be sent to customers following a purchase or interaction, using a friendly and appreciative tone.\n",
      "\n",
      "CRITIQUE:\n",
      "None.\n",
      "\n",
      "---\n",
      "\n",
      "NAIVE PROMPT:\n",
      "\"Please use the provided customer information to read and update their account with any new information or changes. Ensure that all updates are accurately recorded and saved in the customer's account.\"\n",
      "\n",
      "CRITIQUE:\n",
      "None.\n"
     ]
    }
   ],
   "source": [
    "constitution = \"\"\"\n",
    "\n",
    "1. The prompt should not contain a reference to a customer inquiry, review, or other input from a customer.\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "# 2. The prompt should be written in English.\n",
    "\n",
    "\n",
    "def get_llm_critique(constitution, prompt, i):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Here is a prompt written for a large language model(LLM):\n",
    "<prompt>\n",
    "{prompt}\n",
    "</prompt>\n",
    "\n",
    "And here are some rules that the prompt is supposed to follow:\n",
    "\n",
    "<rules>\n",
    "{constitution}\n",
    "</rules>\n",
    "\n",
    "Which rules does this prompt break? If it doesn't break any rules, please respond with \"None\".\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1024,\n",
    "        temperature=0.5,\n",
    "        stream=False\n",
    "    )\n",
    "    str = response['choices'][0]['message']['content']\n",
    "    print(f\"Response {i} received\")\n",
    "    return str\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    critiques = list(executor.map(lambda x: get_llm_critique(\n",
    "        constitution, x[0], x[1]), [(response, i) for i, response in enumerate(naive_responses)]))\n",
    "\n",
    "responseCritiqueString = \"\\n\\n---\\n\\n\".join(\n",
    "    [f\"NAIVE PROMPT:\\n{response}\\n\\nCRITIQUE:\\n{critique}\" for response, critique in zip(naive_responses, critiques)])\n",
    "print(responseCritiqueString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
